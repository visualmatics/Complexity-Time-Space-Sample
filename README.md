# Accuracy: The Bias-Variance Tradeoff
<section name="ff7a" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="0f07" class="graf graf--h3 graf--leading graf--title"></h3><p name="c8fd" class="graf graf--p graf-after--h3">In the article “Which Machine Learning (ML) to choose? <a href="https://medium.com/r/?url=https%3A%2F%2Fwww.linkedin.com%2Fpulse%2Fmachine-learning-101-which-ml-choose-yair-rajwan-ms-dsc" data-href="https://medium.com/r/?url=https%3A%2F%2Fwww.linkedin.com%2Fpulse%2Fmachine-learning-101-which-ml-choose-yair-rajwan-ms-dsc" class="markup--anchor markup--p-anchor" data-tooltip="https://medium.com/r/?url=https%3A%2F%2Fwww.linkedin.com%2Fpulse%2Fmachine-learning-101-which-ml-choose-yair-rajwan-ms-dsc" data-tooltip-position="bottom" data-tooltip-type="link" target="_blank">[1]</a>”, which helps you to choose the right ML for your data, we indicated that “From a business perspective, two of the most significant measurements are accuracy and interpretability.”</p><p name="ac34" class="graf graf--p graf-after--p">We also claimed that “Evaluating the accuracy of a machine learning model is critical in selecting and deploying a machine learning model.”</p><p name="b66f" class="graf graf--p graf-after--p">- <strong class="markup--strong markup--p-strong">But, what factors affect model accuracy?</strong></p><p name="3829" class="graf graf--p graf-after--p">Accuracy is affected by your model fitting. And, model fitting depends on Bias-Variance Tradeoff in machine learning. Balancing bias and variance can solve overfitting and underfitting.</p><figure tabindex="0" contenteditable="false" name="dddb" class="graf graf--figure graf-after--p is-defaultValue"><div class="aspectRatioPlaceholder is-locked" style="max-width: 494px; max-height: 412px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 83.39999999999999%;"></div><img class="graf-image" data-image-id="0*drKk05dVGNtmHnQJ" data-width="494" data-height="412" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/0*drKk05dVGNtmHnQJ"><div class="crosshair u-ignoreBlock"></div></div><figcaption class="imageCaption" contenteditable="true" data-default-value="Type caption for image (optional)"><span class="defaultValue">Type caption for image (optional)</span><br></figcaption></figure><blockquote name="6eea" class="graf graf--blockquote graf-after--figure">Bullseye Diagram: The distribution of model predictions</blockquote><p name="1ba1" class="graf graf--p graf-after--blockquote">Image adapted: Domingo 2012 <a href="https://medium.com/r/?url=https%3A%2F%2Fhomes.cs.washington.edu%2F~pedrod%2Fpapers%2Fcacm12.pdf" data-href="https://medium.com/r/?url=https%3A%2F%2Fhomes.cs.washington.edu%2F~pedrod%2Fpapers%2Fcacm12.pdf" class="markup--anchor markup--p-anchor" rel="nofollow noopener" data-tooltip="https://medium.com/r/?url=https%3A%2F%2Fhomes.cs.washington.edu%2F~pedrod%2Fpapers%2Fcacm12.pdf" data-tooltip-position="bottom" data-tooltip-type="link" target="_blank">[2]</a></p><p name="4b7a" class="graf graf--p graf-after--p">- <strong class="markup--strong markup--p-strong">Definitions:</strong></p><p name="1e6a" class="graf graf--p graf--startsWithDoubleQuote graf-after--p">“Model fitting is a measure of how well [optimize] a machine learning model generalizes to similar [evaluation] data to that on which it was trained. A model that is well-fitted [optimal-fitted] produces more accurate outcomes. A model that is overfitted matches the data too closely. A model that is under-fitted does not match closely enough <a href="https://medium.com/r/?url=https%3A%2F%2Fwww.datarobot.com%2Fwiki%2Ffitting" data-href="https://medium.com/r/?url=https%3A%2F%2Fwww.datarobot.com%2Fwiki%2Ffitting" class="markup--anchor markup--p-anchor" rel="nofollow noopener" data-tooltip="https://medium.com/r/?url=https%3A%2F%2Fwww.datarobot.com%2Fwiki%2Ffitting" data-tooltip-position="bottom" data-tooltip-type="link" target="_blank">[3]</a>.”</p><p name="4bce" class="graf graf--p graf--startsWithDoubleQuote graf-after--p">“In machine learning, overfitting occurs when a learning model customizes itself too much to describe the relationship between training data and the labels. Overfitting tends to make the model very complex by having too many parameters. By doing this, it loses its generalization power, which leads to poor performance on new [evaluation] data <a href="https://medium.com/r/?url=https%3A%2F%2Fprateekvjoshi.com%2F2013%2F06%2F09%2Foverfitting-in-machine-learning" data-href="https://medium.com/r/?url=https%3A%2F%2Fprateekvjoshi.com%2F2013%2F06%2F09%2Foverfitting-in-machine-learning" class="markup--anchor markup--p-anchor" rel="nofollow noopener" data-tooltip="https://medium.com/r/?url=https%3A%2F%2Fprateekvjoshi.com%2F2013%2F06%2F09%2Foverfitting-in-machine-learning" data-tooltip-position="bottom" data-tooltip-type="link" target="_blank">[4]</a>.”</p><p name="deee" class="graf graf--p graf--startsWithDoubleQuote graf-after--p">“Your model is underfitting the training data when the model performs poorly on the training data. This is because the model is unable to capture the relationship between the input examples (often called X) and the target values (often called Y) <a href="https://medium.com/r/?url=https%3A%2F%2Fdocs.aws.amazon.com%2Fmachine-learning%2Flatest%2Fdg%2Fmodel-fit-underfitting-vs-overfitting.html" data-href="https://medium.com/r/?url=https%3A%2F%2Fdocs.aws.amazon.com%2Fmachine-learning%2Flatest%2Fdg%2Fmodel-fit-underfitting-vs-overfitting.html" class="markup--anchor markup--p-anchor" rel="nofollow noopener" data-tooltip="https://medium.com/r/?url=https%3A%2F%2Fdocs.aws.amazon.com%2Fmachine-learning%2Flatest%2Fdg%2Fmodel-fit-underfitting-vs-overfitting.html" data-tooltip-position="bottom" data-tooltip-type="link" target="_blank">[5]</a>.”</p><p name="94fd" class="graf graf--p graf-after--p">- <strong class="markup--strong markup--p-strong">Root causes:</strong></p><p name="c14d" class="graf graf--p graf-after--p">Model fit depends on solving the issue and balancing the tradeoff between bias and variance.</p><p name="da15" class="graf graf--p graf--startsWithDoubleQuote graf-after--p">“Understanding model fit is important for understanding the root cause for poor model accuracy. This understanding will guide you to take corrective steps. We can determine whether a predictive model is underfitting or overfitting the training data by looking at the prediction error on the training data and the evaluation data <a href="https://medium.com/ml-research-lab/under-fitting-over-fitting-and-its-solution-dc6191e34250" data-href="https://medium.com/ml-research-lab/under-fitting-over-fitting-and-its-solution-dc6191e34250" class="markup--anchor markup--p-anchor" rel="nofollow noopener" data-tooltip="https://medium.com/ml-research-lab/under-fitting-over-fitting-and-its-solution-dc6191e34250" data-tooltip-position="bottom" data-tooltip-type="link" target="_blank">[6]</a>.”</p><p name="52bb" class="graf graf--p graf-after--p">Bias is the difference between the estimated value and the true value of the parameter being evaluated. High bias results in underfitting leading to an inaccurate [not valid] model. It can be caused by training on a small data set, building a simple model to capture complex patterns, or not taking into account all the features given for training which causes learning incorrect relations. Generally, high-bias models learn faster and are easy to understand, but they are less flexible <a href="https://medium.com/r/?url=https%3A%2F%2Fmedium.datadriveninvestor.com%2Fdetermining-perfect-fit-for-your-ml-model-339459eef670" data-href="https://medium.com/r/?url=https%3A%2F%2Fmedium.datadriveninvestor.com%2Fdetermining-perfect-fit-for-your-ml-model-339459eef670" class="markup--anchor markup--p-anchor" rel="nofollow noopener" data-tooltip="https://medium.com/r/?url=https%3A%2F%2Fmedium.datadriveninvestor.com%2Fdetermining-perfect-fit-for-your-ml-model-339459eef670" data-tooltip-position="bottom" data-tooltip-type="link" target="_blank">[7]</a>.</p><p name="3f21" class="graf graf--p graf-after--p">Variance is the degree of spread in a data set which indicates how far a set of data points are spread out from their mean [average] value. The variance of an estimated function indicates how much the function is capable of adjusting to the change in a data set. High variance results in overfitting leading to inconsistent [not reliable] model. It can be caused by having too many features, building a more complex model than necessary, or capturing a high noise level. Generally, high variance models tune themselves and are more robust to a changing data set, but they are more complex and overly flexible.</p><p name="49bf" class="graf graf--p graf--startsWithDoubleQuote graf-after--p">“A major difference between machine learning and statistics is their purpose. Machine learning models are designed to make the most accurate predictions possible. Statistical models are designed for inference about the relationships between variables.”</p><p name="c168" class="graf graf--p graf-after--p">Statistical bias is a systematic tendency that causes differences between results and facts. Statistical bias may be introduced at all stages of data analysis: data selection, hypothesis testing, estimator selection, analysis methods, and interpretation.</p><figure tabindex="0" contenteditable="false" name="011d" class="graf graf--figure graf-after--p is-defaultValue"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 525px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 75%;"></div><img class="graf-image" data-image-id="0*UjpIfTPlgcw4MBTI" data-width="960" data-height="720" src="https://cdn-images-1.medium.com/max/800/0*UjpIfTPlgcw4MBTI"><div class="crosshair u-ignoreBlock"></div></div><figcaption class="imageCaption" contenteditable="true" data-default-value="Type caption for image (optional)"><span class="defaultValue">Type caption for image (optional)</span><br></figcaption></figure><p name="3e65" class="graf graf--p graf-after--figure">Statistical bias sources from stages of data analysis. Image: Visual Science Informatics, LLC</p><p name="b933" class="graf graf--p graf-after--p">Systematic error (bias) introduces noisy data with high bias but low variance. Although measurements are inaccurate (not valid), they are consistent (reliable). Repeatable systematic error is associated with faulty equipment or a flawed experimental design and influences a measurement’s accuracy.</p><p name="5a27" class="graf graf--p graf-after--p">Reproducibility error (variance) introduces noisy data with low bias but high variance. Although measurements are accurate (valid), they are inconsistence (not reliable). The repeatable error is due to a measurement process and primarily influences a measurement’s accuracy. Reproducibility refers to the variation in measurements made on a subject under changing conditions.</p><figure tabindex="0" contenteditable="false" name="cfb5" class="graf graf--figure graf-after--p is-defaultValue"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 443px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 63.3%;"></div><img class="graf-image" data-image-id="0*ZAuAH_x83fvUgKEq" data-width="725" data-height="459" src="https://cdn-images-1.medium.com/max/800/0*ZAuAH_x83fvUgKEq"><div class="crosshair u-ignoreBlock"></div></div><figcaption class="imageCaption" contenteditable="true" data-default-value="Type caption for image (optional)"><span class="defaultValue">Type caption for image (optional)</span><br></figcaption></figure><blockquote name="9959" class="graf graf--blockquote graf-after--figure">Bias-Variance Tradeoff</blockquote><figure tabindex="0" contenteditable="false" name="b512" class="graf graf--figure graf-after--blockquote is-defaultValue"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 876px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 125.1%;"></div><img class="graf-image" data-image-id="0*fCibQUZOiIaR-n7m" data-width="1199" data-height="1500" src="https://cdn-images-1.medium.com/max/800/0*fCibQUZOiIaR-n7m"><div class="crosshair u-ignoreBlock"></div></div><figcaption class="imageCaption" contenteditable="true" data-default-value="Type caption for image (optional)"><span class="defaultValue">Type caption for image (optional)</span><br></figcaption></figure><blockquote name="f924" class="graf graf--blockquote graf-after--figure">Underfitting, Optimal-fitting, and Overfitting in Machine Learning</blockquote><p name="a3f1" class="graf graf--p graf-after--blockquote">Images adapted from Scott Fortmann-Roe<a href="https://medium.com/r/?url=http%3A%2F%2Fscott.fortmann-roe.com%2Fdocs%2FBiasVariance.html" data-href="https://medium.com/r/?url=http%3A%2F%2Fscott.fortmann-roe.com%2Fdocs%2FBiasVariance.html" class="markup--anchor markup--p-anchor" rel="nofollow noopener" data-tooltip="https://medium.com/r/?url=http%3A%2F%2Fscott.fortmann-roe.com%2Fdocs%2FBiasVariance.html" data-tooltip-position="bottom" data-tooltip-type="link" target="_blank">[8]</a>, Abhishek Shrivastava<a href="https://medium.com/r/?url=https%3A%2F%2Fwww.kaggle.com%2Fgetting-started%2F166897" data-href="https://medium.com/r/?url=https%3A%2F%2Fwww.kaggle.com%2Fgetting-started%2F166897" class="markup--anchor markup--p-anchor" rel="nofollow noopener" data-tooltip="https://medium.com/r/?url=https%3A%2F%2Fwww.kaggle.com%2Fgetting-started%2F166897" data-tooltip-position="bottom" data-tooltip-type="link" target="_blank">[9]</a>, and Andrew Ng<a href="https://medium.com/r/?url=https%3A%2F%2Fwww.coursera.org%2Flecture%2Fdeep-neural-network%2Fbias-variance-ZhclI" data-href="https://medium.com/r/?url=https%3A%2F%2Fwww.coursera.org%2Flecture%2Fdeep-neural-network%2Fbias-variance-ZhclI" class="markup--anchor markup--p-anchor" rel="nofollow noopener" data-tooltip="https://medium.com/r/?url=https%3A%2F%2Fwww.coursera.org%2Flecture%2Fdeep-neural-network%2Fbias-variance-ZhclI" data-tooltip-position="bottom" data-tooltip-type="link" target="_blank">[10]</a></p><p name="9fe6" class="graf graf--p graf-after--p">- <strong class="markup--strong markup--p-strong">Trade-off:</strong></p><p name="5272" class="graf graf--p graf--startsWithDoubleQuote graf-after--p">“The expected test error of an ML model can be decomposed into its bias and variance through the following formula:</p><p name="a4de" class="graf graf--p graf-after--p">𝙩𝙚𝙨𝙩 𝙚𝙧𝙧𝙤𝙧 = 𝙗𝙞𝙖𝙨² + 𝙫𝙖𝙧𝙞𝙖𝙣𝙘𝙚 + 𝙞𝙧𝙧𝙚𝙙𝙪𝙘𝙞𝙗𝙡𝙚 𝙚𝙧𝙧𝙤𝙧</p><p name="2dc0" class="graf graf--p graf-after--p">So, to decrease the estimation error [to improve accuracy], you need to decrease both the bias and variance, which in general are inversely proportional and hence the trade-off <a href="https://medium.com/r/?url=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-bias-variance-tradeoff-and-visualizing-it-with-example-and-python-code-7af2681a10a7" data-href="https://medium.com/r/?url=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-bias-variance-tradeoff-and-visualizing-it-with-example-and-python-code-7af2681a10a7" class="markup--anchor markup--p-anchor" rel="nofollow noopener" data-tooltip="https://medium.com/r/?url=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-bias-variance-tradeoff-and-visualizing-it-with-example-and-python-code-7af2681a10a7" data-tooltip-position="bottom" data-tooltip-type="link" target="_blank">[11]</a>.”</p><p name="b6bf" class="graf graf--p graf-after--p">Bias and variance trade-off needs to be balanced in order to address the differences in health care in this country and around the world. Increasing bias (not always) reduces variance and vice-versa.</p><p name="e35f" class="graf graf--p graf-after--p">- <strong class="markup--strong markup--p-strong">Remedies:</strong></p><ul class="postList"><li name="2365" class="graf graf--li graf-after--p">Early stopping:</li></ul><p name="507a" class="graf graf--p graf-after--li">One additional effective technique in solving the issue of overfitting and underfitting and building an optimal-fitting ML model is early stopping.</p><p name="24fb" class="graf graf--p graf--startsWithDoubleQuote graf-after--p">“Early stopping is one of the most commonly used strategies because it is straightforward and effective. It refers to the process of stopping the training when the training error is no longer decreasing but the validation error is starting to rise <a href="https://medium.com/r/?url=https%3A%2F%2Ftheaisummer.com%2Fregularization" data-href="https://medium.com/r/?url=https%3A%2F%2Ftheaisummer.com%2Fregularization" class="markup--anchor markup--p-anchor" rel="nofollow noopener" data-tooltip="https://medium.com/r/?url=https%3A%2F%2Ftheaisummer.com%2Fregularization" data-tooltip-position="bottom" data-tooltip-type="link" target="_blank">[12]</a>.”</p><ul class="postList"><li name="e4a9" class="graf graf--li graf-after--p">Ensemble methods:</li></ul><p name="cc60" class="graf graf--p graf-after--li">Combine models via the Boosting ensemble method to decrease the bias. Combine models via the Bagging ensemble method to reduce the variance.</p><ul class="postList"><li name="3836" class="graf graf--li graf-after--p">Visualization</li></ul><p name="264c" class="graf graf--p graf-after--li">Data visualization is a graphical representation of information and data. Using visual elements, such as charts, graphs, and maps, data visualization techniques provide a visual way to see and understand trends, outliers, and patterns in data. Visualization tools provide capabilities that help discover new insights by demonstrating relationships between data.</p><figure tabindex="0" contenteditable="false" name="28ea" class="graf graf--figure graf-after--p is-defaultValue"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 466px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 66.60000000000001%;"></div><img class="graf-image" data-image-id="0*hK9AT-r2pkAoIi1y" data-width="1280" data-height="853" src="https://cdn-images-1.medium.com/max/800/0*hK9AT-r2pkAoIi1y"><div class="crosshair u-ignoreBlock"></div></div><figcaption class="imageCaption" contenteditable="true" data-default-value="Type caption for image (optional)"><span class="defaultValue">Type caption for image (optional)</span><br></figcaption></figure><blockquote name="9a44" class="graf graf--blockquote graf-after--figure">Anscombe’s Quartet</blockquote><p name="fb9e" class="graf graf--p graf-after--blockquote">Image: Schutz <a href="https://medium.com/r/?url=https%3A%2F%2Fcommons.wikimedia.org%2Fwiki%2FUser%3ASchutz" data-href="https://medium.com/r/?url=https%3A%2F%2Fcommons.wikimedia.org%2Fwiki%2FUser%3ASchutz" class="markup--anchor markup--p-anchor" rel="nofollow noopener" data-tooltip="https://medium.com/r/?url=https%3A%2F%2Fcommons.wikimedia.org%2Fwiki%2FUser%3ASchutz" data-tooltip-position="bottom" data-tooltip-type="link" target="_blank">[13]</a></p><p name="cf0f" class="graf graf--p graf-after--p">An additional benefit for visualizing data is that data sets that have similar descriptive statistics, such as mean, variance, correlation, linear regression, and coefficient of determination of the linear regression, yet have very different distributions and appear very different when graphed.</p><p name="de49" class="graf graf--p graf-after--p">Anscombe’s quartet <a href="https://medium.com/r/?url=https%3A%2F%2Fwww.tandfonline.com%2Fdoi%2Fabs%2F10.1080%2F00031305.1973.10478966" data-href="https://medium.com/r/?url=https%3A%2F%2Fwww.tandfonline.com%2Fdoi%2Fabs%2F10.1080%2F00031305.1973.10478966" class="markup--anchor markup--p-anchor" rel="nofollow noopener" data-tooltip="https://medium.com/r/?url=https%3A%2F%2Fwww.tandfonline.com%2Fdoi%2Fabs%2F10.1080%2F00031305.1973.10478966" data-tooltip-position="bottom" data-tooltip-type="link" target="_blank">[14]</a>, in the above image, comprises four data sets that demonstrate both the importance of graphing data when analyzing it and the effect of outliers and other influential observations on statistical properties.</p><p name="dcf1" class="graf graf--p graf-after--p">In ML, the three major reasons, for data visualization, are for understanding, diagnosis, and refinement of your model.</p><p name="3d7e" class="graf graf--p graf-after--p">One important purpose, you need to visualize your model, is for providing an interpretable (reasoning) predictive model and explainability of your model. Other significant purposes are visualizing your model architecture, parameters, and metrics.</p><p name="68d3" class="graf graf--p graf-after--p">Also, you might need to visualize your model during debugging and improvements, comparison and selection, and teaching concepts.</p><p name="93db" class="graf graf--p graf-after--p">Visualization is most relevant during training for monitoring and observing a number of metrics and tracking of model training progression. After training, visualizing model inference is the process of drawing conclusions out of a trained model. Visualizing the results helps in interpreting and retracing how the model generates its estimates (Visualizing Machine Learning Models: Guide and Tools <a href="https://medium.com/r/?url=https%3A%2F%2Fneptune.ai%2Fblog%2Fvisualizing-machine-learning-models" data-href="https://medium.com/r/?url=https%3A%2F%2Fneptune.ai%2Fblog%2Fvisualizing-machine-learning-models" class="markup--anchor markup--p-anchor" rel="nofollow noopener" data-tooltip="https://medium.com/r/?url=https%3A%2F%2Fneptune.ai%2Fblog%2Fvisualizing-machine-learning-models" data-tooltip-position="bottom" data-tooltip-type="link" target="_blank">[15]</a>).</p><ul class="postList"><li name="4992" class="graf graf--li graf-after--p">Confusion Matrix and Classification Evaluation Metrics</li></ul><p name="b70d" class="graf graf--p graf-after--li">Once you fit your ML model, you must evaluate its performance on a test dataset.</p><p name="defb" class="graf graf--p graf-after--p">Evaluating your model performance is critical, as your model performance allows you to choose between candidate models and to communicate how reasonable the model is at solving the problem.</p><p name="2e70" class="graf graf--p graf-after--p">Measuring, for instance, a binary output prediction (Classification) is captured in a specific table layout&hairsp;—&hairsp;a Confusion Matrix, which visualizes whether a model is confusing two classes. Each row of the matrix represents the instances in an actual class, while each column represents the instances in a predicted class. Four measures are captured: True Positive, False Negative, False Positive, and True Negative.</p><p name="0485" class="graf graf--p graf-after--p">Calculating accuracy is derived from the four values in a confusion matrix. Additional metrics with formulas on the right and below are Classification Evaluation Metrics. These metrics include but are not limited to the following: Sensitivity, Specificity, Accuracy, Negative Predictive Value, and Precision.</p><figure tabindex="0" contenteditable="false" name="b92b" class="graf graf--figure graf-after--p is-defaultValue"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 395px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 56.49999999999999%;"></div><img class="graf-image" data-image-id="0*hYttgcaVoEfNUgvQ" data-width="974" data-height="550" src="https://cdn-images-1.medium.com/max/800/0*hYttgcaVoEfNUgvQ"><div class="crosshair u-ignoreBlock"></div></div><figcaption class="imageCaption" contenteditable="true" data-default-value="Type caption for image (optional)"><span class="defaultValue">Type caption for image (optional)</span><br></figcaption></figure><p name="7e98" class="graf graf--p graf-after--figure">Confusion Matrix and Classification Evaluation Metrics. Image: Maninder Virk</p><p name="5807" class="graf graf--p graf-after--p">In addition to accuracy, there are numerous model evaluation metrics. Three metrics that are commonly reported for a model on a binary classification problem are:</p><ul class="postList"><li name="c6f5" class="graf graf--li graf-after--p">Precision</li><li name="8e89" class="graf graf--li graf-after--li">Recall</li><li name="fb0b" class="graf graf--li graf-after--li">F1 score</li></ul><p name="a596" class="graf graf--p graf-after--li">Precision quantifies the number of positive class predictions that actually belong to the positive class. Recall quantifies the number of positive class predictions made out of all positive examples in the dataset. The F1 score combines the precision and recall of a classifier into a single metric by taking their harmonic mean. It is primarily used to compare the performance of two finer-grained classifiers.</p><figure tabindex="0" contenteditable="false" name="bb25" class="graf graf--figure graf-after--p is-defaultValue"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 525px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 75%;"></div><img class="graf-image" data-image-id="0*XCi1tA7uN4Ks13H_" data-width="960" data-height="720" src="https://cdn-images-1.medium.com/max/800/0*XCi1tA7uN4Ks13H_"><div class="crosshair u-ignoreBlock"></div></div><figcaption class="imageCaption" contenteditable="true" data-default-value="Type caption for image (optional)"><span class="defaultValue">Type caption for image (optional)</span><br></figcaption></figure><p name="fc53" class="graf graf--p graf-after--figure">Hierarchy of Metrics from labeled training data and classifier predictions to F1 score. Adapted Image: Teemu Kanstrén</p><p name="cfe7" class="graf graf--p graf--startsWithDoubleQuote graf-after--p">“The metrics form a hierarchy that starts by counting the true/false negatives/positives, at the bottom, continues by calculating the Precision and Recall/Sensitivity metrics, and builds up by combining them to calculate the F1 score <a href="https://medium.com/r/?url=https%3A%2F%2Ftowardsdatascience.com%2Fa-look-at-precision-recall-and-f1-score-36b5fd0dd3ec" data-href="https://medium.com/r/?url=https%3A%2F%2Ftowardsdatascience.com%2Fa-look-at-precision-recall-and-f1-score-36b5fd0dd3ec" class="markup--anchor markup--p-anchor" rel="nofollow noopener" data-tooltip="https://medium.com/r/?url=https%3A%2F%2Ftowardsdatascience.com%2Fa-look-at-precision-recall-and-f1-score-36b5fd0dd3ec" data-tooltip-position="bottom" data-tooltip-type="link" target="_blank">[16]</a>.”</p><p name="536a" class="graf graf--p graf-after--p">The importance and interpretation of evaluation metrics depend on the domain and context of your ML model. For instance, medical tests are evaluated by specificity and sensitivity, while information retrieval systems are evaluated by precision and recall. Understanding the differences between precision and recall vs. specificity and sensitivity is significant in your model evaluation within a specific domain <a href="https://medium.com/r/?url=https%3A%2F%2Ftowardsdatascience.com%2Fshould-i-look-at-precision-recall-or-specificity-sensitivity-3946158aace1" data-href="https://medium.com/r/?url=https%3A%2F%2Ftowardsdatascience.com%2Fshould-i-look-at-precision-recall-or-specificity-sensitivity-3946158aace1" class="markup--anchor markup--p-anchor" rel="nofollow noopener" data-tooltip="https://medium.com/r/?url=https%3A%2F%2Ftowardsdatascience.com%2Fshould-i-look-at-precision-recall-or-specificity-sensitivity-3946158aace1" data-tooltip-position="bottom" data-tooltip-type="link" target="_blank">[17]</a>.</p><figure tabindex="0" contenteditable="false" name="5e37" class="graf graf--figure graf-after--p is-defaultValue"><div class="aspectRatioPlaceholder is-locked" style="max-width: 700px; max-height: 323px;"><div class="aspectRatioPlaceholder-fill" style="padding-bottom: 46.1%;"></div><img class="graf-image" data-image-id="0*ShfJEdZqCCadFaou" data-width="1986" data-height="915" src="https://cdn-images-1.medium.com/max/800/0*ShfJEdZqCCadFaou"><div class="crosshair u-ignoreBlock"></div></div><figcaption class="imageCaption" contenteditable="true" data-default-value="Type caption for image (optional)"><span class="defaultValue">Type caption for image (optional)</span><br></figcaption></figure><p name="7819" class="graf graf--p graf-after--figure">Bias vs. Variance of ML Algorithms. Image: Ega Skura</p><p name="313b" class="graf graf--p graf-after--p">For ML model builders understanding how accuracy is affected by their model fitting is essential. Building an accurate classification model can correctly classify positives from negatives.</p><p name="2745" class="graf graf--p graf-after--p">- <strong class="markup--strong markup--p-strong">In essence:</strong></p><p name="fede" class="graf graf--p graf--startsWithDoubleQuote graf-after--p">“Balancing bias and variance&nbsp;… is the best way to ensure that model is sufficiently [optimally] fit on the data and performs well on new [evaluation] data.” Solving the issue of bias and variance is about dealing with overfitting and underfitting and building an optimal model.</p><p name="fbce" class="graf graf--p graf-after--p">Next, read my “Complexity&hairsp;—&hairsp;Time, Space, &amp; Sample” article at <a href="https://medium.com/r/?url=https%3A%2F%2Fwww.linkedin.com%2Fpulse%2Fcomplexity-time-space-sample-yair-rajwan-ms-dsc" data-href="https://medium.com/r/?url=https%3A%2F%2Fwww.linkedin.com%2Fpulse%2Fcomplexity-time-space-sample-yair-rajwan-ms-dsc" class="markup--anchor markup--p-anchor" target="_blank">https://www.linkedin.com/pulse/complexity-time-space-sample-yair-rajwan-ms-dsc</a></p><p name="b26a" class="graf graf--p graf-after--p">—&hairsp;—&hairsp;—&hairsp;—&hairsp;—&hairsp;—&hairsp;—&hairsp;—&hairsp;—&hairsp;—&hairsp;—&hairsp;—&hairsp;—&hairsp;—&hairsp;—&hairsp;—&hairsp;—&hairsp;—&hairsp;—&hairsp;—&hairsp;—&hairsp;—&hairsp;—&hairsp;—&hairsp;—&hairsp;—&hairsp;—&hairsp;—&hairsp;-</p><p name="0b77" class="graf graf--p graf-after--p"><a href="https://medium.com/r/?url=https%3A%2F%2Fwww.linkedin.com%2Fpulse%2Fmachine-learning-101-which-ml-choose-yair-rajwan-ms-dsc" data-href="https://medium.com/r/?url=https%3A%2F%2Fwww.linkedin.com%2Fpulse%2Fmachine-learning-101-which-ml-choose-yair-rajwan-ms-dsc" class="markup--anchor markup--p-anchor" data-tooltip="https://medium.com/r/?url=https%3A%2F%2Fwww.linkedin.com%2Fpulse%2Fmachine-learning-101-which-ml-choose-yair-rajwan-ms-dsc" data-tooltip-position="bottom" data-tooltip-type="link" target="_blank">[1]</a> <a href="https://medium.com/r/?url=https%3A%2F%2Fwww.linkedin.com%2Fpulse%2Fmachine-learning-101-which-ml-choose-yair-rajwan-ms-dsc" data-href="https://medium.com/r/?url=https%3A%2F%2Fwww.linkedin.com%2Fpulse%2Fmachine-learning-101-which-ml-choose-yair-rajwan-ms-dsc" class="markup--anchor markup--p-anchor" target="_blank">https://www.linkedin.com/pulse/machine-learning-101-which-ml-choose-yair-rajwan-ms-dsc</a></p><p name="1f10" class="graf graf--p graf-after--p"><a href="https://medium.com/r/?url=https%3A%2F%2Fhomes.cs.washington.edu%2F~pedrod%2Fpapers%2Fcacm12.pdf" data-href="https://medium.com/r/?url=https%3A%2F%2Fhomes.cs.washington.edu%2F~pedrod%2Fpapers%2Fcacm12.pdf" class="markup--anchor markup--p-anchor" rel="nofollow noopener" data-tooltip="https://medium.com/r/?url=https%3A%2F%2Fhomes.cs.washington.edu%2F~pedrod%2Fpapers%2Fcacm12.pdf" data-tooltip-position="bottom" data-tooltip-type="link" target="_blank">[2]</a> <a href="https://medium.com/r/?url=https%3A%2F%2Fhomes.cs.washington.edu%2F~pedrod%2Fpapers%2Fcacm12.pdf" data-href="https://medium.com/r/?url=https%3A%2F%2Fhomes.cs.washington.edu%2F~pedrod%2Fpapers%2Fcacm12.pdf" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf</a></p><p name="673e" class="graf graf--p graf-after--p"><a href="https://medium.com/r/?url=https%3A%2F%2Fwww.datarobot.com%2Fwiki%2Ffitting" data-href="https://medium.com/r/?url=https%3A%2F%2Fwww.datarobot.com%2Fwiki%2Ffitting" class="markup--anchor markup--p-anchor" rel="nofollow noopener" data-tooltip="https://medium.com/r/?url=https%3A%2F%2Fwww.datarobot.com%2Fwiki%2Ffitting" data-tooltip-position="bottom" data-tooltip-type="link" target="_blank">[3]</a> <a href="https://medium.com/r/?url=https%3A%2F%2Fwww.datarobot.com%2Fwiki%2Ffitting" data-href="https://medium.com/r/?url=https%3A%2F%2Fwww.datarobot.com%2Fwiki%2Ffitting" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">https://www.datarobot.com/wiki/fitting</a></p><p name="fdb8" class="graf graf--p graf-after--p"><a href="https://medium.com/r/?url=https%3A%2F%2Fprateekvjoshi.com%2F2013%2F06%2F09%2Foverfitting-in-machine-learning" data-href="https://medium.com/r/?url=https%3A%2F%2Fprateekvjoshi.com%2F2013%2F06%2F09%2Foverfitting-in-machine-learning" class="markup--anchor markup--p-anchor" rel="nofollow noopener" data-tooltip="https://medium.com/r/?url=https%3A%2F%2Fprateekvjoshi.com%2F2013%2F06%2F09%2Foverfitting-in-machine-learning" data-tooltip-position="bottom" data-tooltip-type="link" target="_blank">[4]</a> <a href="https://medium.com/r/?url=https%3A%2F%2Fprateekvjoshi.com%2F2013%2F06%2F09%2Foverfitting-in-machine-learning" data-href="https://medium.com/r/?url=https%3A%2F%2Fprateekvjoshi.com%2F2013%2F06%2F09%2Foverfitting-in-machine-learning" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">https://prateekvjoshi.com/2013/06/09/overfitting-in-machine-learning</a></p><p name="4333" class="graf graf--p graf-after--p"><a href="https://medium.com/r/?url=https%3A%2F%2Fdocs.aws.amazon.com%2Fmachine-learning%2Flatest%2Fdg%2Fmodel-fit-underfitting-vs-overfitting.html" data-href="https://medium.com/r/?url=https%3A%2F%2Fdocs.aws.amazon.com%2Fmachine-learning%2Flatest%2Fdg%2Fmodel-fit-underfitting-vs-overfitting.html" class="markup--anchor markup--p-anchor" rel="nofollow noopener" data-tooltip="https://medium.com/r/?url=https%3A%2F%2Fdocs.aws.amazon.com%2Fmachine-learning%2Flatest%2Fdg%2Fmodel-fit-underfitting-vs-overfitting.html" data-tooltip-position="bottom" data-tooltip-type="link" target="_blank">[5]</a> <a href="https://medium.com/r/?url=https%3A%2F%2Fdocs.aws.amazon.com%2Fmachine-learning%2Flatest%2Fdg%2Fmodel-fit-underfitting-vs-overfitting.html" data-href="https://medium.com/r/?url=https%3A%2F%2Fdocs.aws.amazon.com%2Fmachine-learning%2Flatest%2Fdg%2Fmodel-fit-underfitting-vs-overfitting.html" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">https://docs.aws.amazon.com/machine-learning/latest/dg/model-fit-underfitting-vs-overfitting.html</a></p><p name="d1e4" class="graf graf--p graf-after--p"><a href="https://medium.com/ml-research-lab/under-fitting-over-fitting-and-its-solution-dc6191e34250" data-href="https://medium.com/ml-research-lab/under-fitting-over-fitting-and-its-solution-dc6191e34250" class="markup--anchor markup--p-anchor" rel="nofollow noopener" data-tooltip="https://medium.com/ml-research-lab/under-fitting-over-fitting-and-its-solution-dc6191e34250" data-tooltip-position="bottom" data-tooltip-type="link" target="_blank">[6]</a> <a href="https://medium.com/ml-research-lab/under-fitting-over-fitting-and-its-solution-dc6191e34250" data-href="https://medium.com/ml-research-lab/under-fitting-over-fitting-and-its-solution-dc6191e34250" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">https://medium.com/ml-research-lab/under-fitting-over-fitting-and-its-solution-dc6191e34250</a></p><p name="43ef" class="graf graf--p graf-after--p"><a href="https://medium.com/r/?url=https%3A%2F%2Fmedium.datadriveninvestor.com%2Fdetermining-perfect-fit-for-your-ml-model-339459eef670" data-href="https://medium.com/r/?url=https%3A%2F%2Fmedium.datadriveninvestor.com%2Fdetermining-perfect-fit-for-your-ml-model-339459eef670" class="markup--anchor markup--p-anchor" rel="nofollow noopener" data-tooltip="https://medium.com/r/?url=https%3A%2F%2Fmedium.datadriveninvestor.com%2Fdetermining-perfect-fit-for-your-ml-model-339459eef670" data-tooltip-position="bottom" data-tooltip-type="link" target="_blank">[7]</a> <a href="https://medium.com/r/?url=https%3A%2F%2Fmedium.datadriveninvestor.com%2Fdetermining-perfect-fit-for-your-ml-model-339459eef670" data-href="https://medium.com/r/?url=https%3A%2F%2Fmedium.datadriveninvestor.com%2Fdetermining-perfect-fit-for-your-ml-model-339459eef670" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">https://medium.datadriveninvestor.com/determining-perfect-fit-for-your-ml-model-339459eef670</a></p><p name="3b7e" class="graf graf--p graf-after--p"><a href="https://medium.com/r/?url=http%3A%2F%2Fscott.fortmann-roe.com%2Fdocs%2FBiasVariance.html" data-href="https://medium.com/r/?url=http%3A%2F%2Fscott.fortmann-roe.com%2Fdocs%2FBiasVariance.html" class="markup--anchor markup--p-anchor" rel="nofollow noopener" data-tooltip="https://medium.com/r/?url=http%3A%2F%2Fscott.fortmann-roe.com%2Fdocs%2FBiasVariance.html" data-tooltip-position="bottom" data-tooltip-type="link" target="_blank">[8]</a> <a href="https://medium.com/r/?url=http%3A%2F%2Fscott.fortmann-roe.com%2Fdocs%2FBiasVariance.html" data-href="https://medium.com/r/?url=http%3A%2F%2Fscott.fortmann-roe.com%2Fdocs%2FBiasVariance.html" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">http://scott.fortmann-roe.com/docs/BiasVariance.html</a></p><p name="3f4c" class="graf graf--p graf-after--p"><a href="https://medium.com/r/?url=https%3A%2F%2Fwww.kaggle.com%2Fgetting-started%2F166897" data-href="https://medium.com/r/?url=https%3A%2F%2Fwww.kaggle.com%2Fgetting-started%2F166897" class="markup--anchor markup--p-anchor" rel="nofollow noopener" data-tooltip="https://medium.com/r/?url=https%3A%2F%2Fwww.kaggle.com%2Fgetting-started%2F166897" data-tooltip-position="bottom" data-tooltip-type="link" target="_blank">[9]</a> <a href="https://medium.com/r/?url=https%3A%2F%2Fwww.kaggle.com%2Fgetting-started%2F166897" data-href="https://medium.com/r/?url=https%3A%2F%2Fwww.kaggle.com%2Fgetting-started%2F166897" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">https://www.kaggle.com/getting-started/166897</a></p><p name="a30c" class="graf graf--p graf-after--p"><a href="https://medium.com/r/?url=https%3A%2F%2Fwww.coursera.org%2Flecture%2Fdeep-neural-network%2Fbias-variance-ZhclI" data-href="https://medium.com/r/?url=https%3A%2F%2Fwww.coursera.org%2Flecture%2Fdeep-neural-network%2Fbias-variance-ZhclI" class="markup--anchor markup--p-anchor" rel="nofollow noopener" data-tooltip="https://medium.com/r/?url=https%3A%2F%2Fwww.coursera.org%2Flecture%2Fdeep-neural-network%2Fbias-variance-ZhclI" data-tooltip-position="bottom" data-tooltip-type="link" target="_blank">[10]</a> <a href="https://medium.com/r/?url=https%3A%2F%2Fwww.coursera.org%2Flecture%2Fdeep-neural-network%2Fbias-variance-ZhclI" data-href="https://medium.com/r/?url=https%3A%2F%2Fwww.coursera.org%2Flecture%2Fdeep-neural-network%2Fbias-variance-ZhclI" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">https://www.coursera.org/lecture/deep-neural-network/bias-variance-ZhclI</a></p><p name="9b03" class="graf graf--p graf-after--p"><a href="https://medium.com/r/?url=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-bias-variance-tradeoff-and-visualizing-it-with-example-and-python-code-7af2681a10a7" data-href="https://medium.com/r/?url=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-bias-variance-tradeoff-and-visualizing-it-with-example-and-python-code-7af2681a10a7" class="markup--anchor markup--p-anchor" rel="nofollow noopener" data-tooltip="https://medium.com/r/?url=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-bias-variance-tradeoff-and-visualizing-it-with-example-and-python-code-7af2681a10a7" data-tooltip-position="bottom" data-tooltip-type="link" target="_blank">[11]</a> <a href="https://medium.com/r/?url=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-bias-variance-tradeoff-and-visualizing-it-with-example-and-python-code-7af2681a10a7" data-href="https://medium.com/r/?url=https%3A%2F%2Ftowardsdatascience.com%2Funderstanding-the-bias-variance-tradeoff-and-visualizing-it-with-example-and-python-code-7af2681a10a7" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-and-visualizing-it-with-example-and-python-code-7af2681a10a7</a></p><p name="0d6b" class="graf graf--p graf-after--p"><a href="https://medium.com/r/?url=https%3A%2F%2Ftheaisummer.com%2Fregularization" data-href="https://medium.com/r/?url=https%3A%2F%2Ftheaisummer.com%2Fregularization" class="markup--anchor markup--p-anchor" rel="nofollow noopener" data-tooltip="https://medium.com/r/?url=https%3A%2F%2Ftheaisummer.com%2Fregularization" data-tooltip-position="bottom" data-tooltip-type="link" target="_blank">[12]</a> <a href="https://medium.com/r/?url=https%3A%2F%2Ftheaisummer.com%2Fregularization" data-href="https://medium.com/r/?url=https%3A%2F%2Ftheaisummer.com%2Fregularization" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">https://theaisummer.com/regularization</a></p><p name="9ba8" class="graf graf--p graf-after--p"><a href="https://medium.com/r/?url=https%3A%2F%2Fcommons.wikimedia.org%2Fwiki%2FUser%3ASchutz" data-href="https://medium.com/r/?url=https%3A%2F%2Fcommons.wikimedia.org%2Fwiki%2FUser%3ASchutz" class="markup--anchor markup--p-anchor" rel="nofollow noopener" data-tooltip="https://medium.com/r/?url=https%3A%2F%2Fcommons.wikimedia.org%2Fwiki%2FUser%3ASchutz" data-tooltip-position="bottom" data-tooltip-type="link" target="_blank">[13]</a> <a href="https://medium.com/r/?url=https%3A%2F%2Fcommons.wikimedia.org%2Fwiki%2FUser%3ASchutz" data-href="https://medium.com/r/?url=https%3A%2F%2Fcommons.wikimedia.org%2Fwiki%2FUser%3ASchutz" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">https://commons.wikimedia.org/wiki/User:Schutz</a></p><p name="e0d8" class="graf graf--p graf-after--p"><a href="https://medium.com/r/?url=https%3A%2F%2Fwww.tandfonline.com%2Fdoi%2Fabs%2F10.1080%2F00031305.1973.10478966" data-href="https://medium.com/r/?url=https%3A%2F%2Fwww.tandfonline.com%2Fdoi%2Fabs%2F10.1080%2F00031305.1973.10478966" class="markup--anchor markup--p-anchor" rel="nofollow noopener" data-tooltip="https://medium.com/r/?url=https%3A%2F%2Fwww.tandfonline.com%2Fdoi%2Fabs%2F10.1080%2F00031305.1973.10478966" data-tooltip-position="bottom" data-tooltip-type="link" target="_blank">[14]</a> <a href="https://medium.com/r/?url=https%3A%2F%2Fwww.tandfonline.com%2Fdoi%2Fabs%2F10.1080%2F00031305.1973.10478966" data-href="https://medium.com/r/?url=https%3A%2F%2Fwww.tandfonline.com%2Fdoi%2Fabs%2F10.1080%2F00031305.1973.10478966" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">https://www.tandfonline.com/doi/abs/10.1080/00031305.1973.10478966</a></p><p name="8904" class="graf graf--p graf-after--p"><a href="https://medium.com/r/?url=https%3A%2F%2Fneptune.ai%2Fblog%2Fvisualizing-machine-learning-models" data-href="https://medium.com/r/?url=https%3A%2F%2Fneptune.ai%2Fblog%2Fvisualizing-machine-learning-models" class="markup--anchor markup--p-anchor" rel="nofollow noopener" data-tooltip="https://medium.com/r/?url=https%3A%2F%2Fneptune.ai%2Fblog%2Fvisualizing-machine-learning-models" data-tooltip-position="bottom" data-tooltip-type="link" target="_blank">[15]</a> <a href="https://medium.com/r/?url=https%3A%2F%2Fneptune.ai%2Fblog%2Fvisualizing-machine-learning-models" data-href="https://medium.com/r/?url=https%3A%2F%2Fneptune.ai%2Fblog%2Fvisualizing-machine-learning-models" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">https://neptune.ai/blog/visualizing-machine-learning-models</a></p><p name="ba36" class="graf graf--p graf-after--p"><a href="https://medium.com/r/?url=https%3A%2F%2Ftowardsdatascience.com%2Fa-look-at-precision-recall-and-f1-score-36b5fd0dd3ec" data-href="https://medium.com/r/?url=https%3A%2F%2Ftowardsdatascience.com%2Fa-look-at-precision-recall-and-f1-score-36b5fd0dd3ec" class="markup--anchor markup--p-anchor" rel="nofollow noopener" data-tooltip="https://medium.com/r/?url=https%3A%2F%2Ftowardsdatascience.com%2Fa-look-at-precision-recall-and-f1-score-36b5fd0dd3ec" data-tooltip-position="bottom" data-tooltip-type="link" target="_blank">[16]</a> <a href="https://medium.com/r/?url=https%3A%2F%2Ftowardsdatascience.com%2Fa-look-at-precision-recall-and-f1-score-36b5fd0dd3ec" data-href="https://medium.com/r/?url=https%3A%2F%2Ftowardsdatascience.com%2Fa-look-at-precision-recall-and-f1-score-36b5fd0dd3ec" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">https://towardsdatascience.com/a-look-at-precision-recall-and-f1-score-36b5fd0dd3ec</a></p><p name="39a9" class="graf graf--p graf-after--p graf--trailing">[<a href="https://medium.com/r/?url=https%3A%2F%2Ftowardsdatascience.com%2Fshould-i-look-at-precision-recall-or-specificity-sensitivity-3946158aace1" data-href="https://medium.com/r/?url=https%3A%2F%2Ftowardsdatascience.com%2Fshould-i-look-at-precision-recall-or-specificity-sensitivity-3946158aace1" class="markup--anchor markup--p-anchor" rel="nofollow noopener" data-tooltip="https://medium.com/r/?url=https%3A%2F%2Ftowardsdatascience.com%2Fshould-i-look-at-precision-recall-or-specificity-sensitivity-3946158aace1" data-tooltip-position="bottom" data-tooltip-type="link" target="_blank">17</a>] <a href="https://medium.com/r/?url=https%3A%2F%2Ftowardsdatascience.com%2Fshould-i-look-at-precision-recall-or-specificity-sensitivity-3946158aace1" data-href="https://medium.com/r/?url=https%3A%2F%2Ftowardsdatascience.com%2Fshould-i-look-at-precision-recall-or-specificity-sensitivity-3946158aace1" class="markup--anchor markup--p-anchor" rel="nofollow noopener" target="_blank">https://towardsdatascience.com/should-i-look-at-precision-recall-or-specificity-sensitivity-3946158aace1</a></p></div></div></section>
